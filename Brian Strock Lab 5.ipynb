{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shapely, \\\n",
    "    matplotlib,  \\\n",
    "    fiona,\\\n",
    "    numpy as np, \\\n",
    "    pandas as pd, \\\n",
    "    geopandas as gpd, \\\n",
    "    matplotlib.pyplot as plt, \\\n",
    "    geoplot as gplt, \\\n",
    "    mapclassify as mcs, \\\n",
    "    seaborn as sns, \\\n",
    "    pysal as ps,\\\n",
    "    libpysal as lps, \\\n",
    "    math\n",
    "\n",
    "# import packages\n",
    "\n",
    "from esda.moran import Moran\n",
    "from mgwr.gwr import GWR\n",
    "from mgwr.sel_bw import Sel_BW\n",
    "from libpysal.cg.voronoi import voronoi, voronoi_frames\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% import dependencies\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# as this is a large, census-tract level dataset, data has been pre-selected for the state of Minnesota\n",
    "# future revisions will be able to operate on any state and county\n",
    "\n",
    "svi = gpd.read_file(\"/Users/brianstrock/Downloads/Minnesota/SVI2018_MINNESOTA_tract.shp\")\n",
    "svi = svi.to_crs(\"EPSG:4326\")\n",
    "svi = svi.loc[svi['COUNTY'] == \"Ramsey\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% first dataset:  SVI data, US CDC, 2018\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# geocoded from addresses via ESRI geocoding service\n",
    "# also pre-selected for state of Minnesota\n",
    "\n",
    "tri = gpd.read_file(\"/Users/brianstrock/GIS/579Lab5/tri_mn.shp\")\n",
    "tri['trifd'] = tri['trifd'].astype(str)\n",
    "tri = tri.reset_index().set_index('trifd')\n",
    "tri = tri.loc[tri[\"subregion\"] == \"Ramsey County\"]\n",
    "triKey = tri.index.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% second dataset:  TRI data, US EPA, 2018 (geometry)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this is a HUGE dataset- 20k rows, 185 columns.  As a result, columns of interest are extracted at import.\n",
    "\n",
    "fields = ['total_air_emissions', 'total_surface_water_discharge', 'on_site_landfills_release_pounds', 'on_site_underground_inj_release_pounds', 'trifd', 'cas_number']\n",
    "\n",
    "triReleases = pd.read_csv(\"~/Downloads/tri-releases.csv\",\n",
    "                          encoding=\"utf-8\",\n",
    "                          usecols=fields\n",
    "                          )\n",
    "\n",
    "# dtype conversion, fill na values to avoid errors calculating on np.nan down the road\n",
    "\n",
    "triReleases['trifd'] = triReleases['trifd'].astype(str)\n",
    "triReleases = triReleases.fillna(0)\n",
    "\n",
    "# our X variable of interest will be total releases from site- sum of all emissions types\n",
    "# emissions types:  air, surface water, underground injection, on-site landfill\n",
    "# tri data includes both release and transfer data- transfer data is omitted under the assumption\n",
    "# that transfers from one site may be released at another, thus causing duplication\n",
    "\n",
    "triReleases['total_emissions'] = triReleases['total_air_emissions'].astype(float) + triReleases['total_surface_water_discharge'].astype(float) + triReleases['on_site_landfills_release_pounds'].astype(float) + triReleases['on_site_underground_inj_release_pounds'].astype(float)\n",
    "triReleases = triReleases[triReleases.trifd.isin(triKey)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% third dataset:  TRI data, US EPA, 2018 (releases)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this dataset indexes TRI-regulated chemicals by their known effects\n",
    "\n",
    "chemicals = pd.read_csv(\"~/Downloads/chemical-effects.csv\",\n",
    "                        encoding=\"utf-8\",\n",
    "                        sep=',',\n",
    "                        index_col='cas'\n",
    "                        )\n",
    "\n",
    "# change this to change chemical family of interest\n",
    "chemIG = chemicals.loc[chemicals['osha_carcinogens'] == 'X']  # select only carcinogens\n",
    "\n",
    "chemIG = pd.Series(chemIG.osha_carcinogens,\n",
    "                   index=chemIG.index,\n",
    "                   name='chemicals: interest group (CAS)'\n",
    "                   )\n",
    "\n",
    "# this list serves as a key which will filter TRI sites based on chemical family of interest\n",
    "\n",
    "chemIGkey = chemIG.index.to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% fourth dataset:  chemical effects\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As the EPA points out in the TRI dataset, not all emissions are created equal...\n",
    "# some compounds, like dioxins, are extremely toxic at miniscule doses, while others rise\n",
    "# to the level of reportable, but require relatively large concentrations to cause effect.\n",
    "\n",
    "# Furthermore, toxicity can be influenced by factors such as exposure over time and ingestion route.\n",
    "# To address this, the EPA has created TOXICITY WEIGHTS for all TRI-regulated chemicals.\n",
    "# These weights act as scalar values which allow for relative toxicity to be accounted for when comparing\n",
    "# releases.  More details available through EPA's TRI Methodology documentation.\n",
    "\n",
    "# In this model, our response variable will be WEIGHTED EMISSIONS, IE emissions * toxicity weight\n",
    "# NOTE:  Toxicity weight chosen is the highest of 4 possible options, which vary based on ingestion route, etc.\n",
    "# Future versions could account for proper selection of toxicity weights based on site and release characteristics.\n",
    "\n",
    "tox = pd.read_csv(\"~/Downloads/rsei_toxicity.csv\",\n",
    "                  encoding='utf-8',\n",
    "                  index_col=\"CASNumber\"\n",
    "                  )\n",
    "\n",
    "tox['MaxTW'] = tox['MaxTW'].astype(float) # dtype conversion\n",
    "\n",
    "tox = tox[tox.index.isin(chemIGkey)]\n",
    "\n",
    "tox = pd.Series(index=tox.index,\n",
    "                data=tox['MaxTW']\n",
    "                )\n",
    "\n",
    "# this dictionary is our key to locating the correct scalar value for a given toxic chemical\n",
    "toxDict = tox.to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% fifth dataset: chemical toxic weights\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "triReleases = triReleases[triReleases['cas_number'].isin(chemIGkey)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% this mask filters TRI releases based on the chosen chemical effect family\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# at the very least, I plan to update this so that it's operating off of list comprehensions.\n",
    "# Anyway, the purpose of this code is to calculate WEIGHTED EMISSIONS.\n",
    "\n",
    "siteList = []\n",
    "weightList = []\n",
    "\n",
    "for row in triReleases.iterrows():\n",
    "    site = row[1]['trifd']\n",
    "    cas = row[1]['cas_number']\n",
    "    emissions = row[1]['total_emissions']\n",
    "    if cas in toxDict.keys():\n",
    "        weighted = emissions * toxDict[cas]\n",
    "        weightList.append(weighted)\n",
    "        siteList.append(site)\n",
    "    else:\n",
    "        weightList.append(emissions)\n",
    "        siteList.append(site)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% WARNING:  ugly code ahead.  I know it's using iterrows with pandas.  You've been warned.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# As we're using weighted X metrics (population demographics), our Y variable is weighted as percent of total\n",
    "\n",
    "releaseIG = pd.Series(index=siteList, data=weightList, name='weighted_emissions')\n",
    "releaseIG = releaseIG.fillna(0)\n",
    "releaseIG = releaseIG.groupby([releaseIG.index]).sum()\n",
    "releaseIG = pd.Series(releaseIG)\n",
    "releaseIG = releaseIG.div(np.sum(releaseIG))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Release Interest Group: our Y variable (response)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "triIG = pd.merge(tri, releaseIG, left_index=True, right_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Now that we've calculated weighted releases, this data can be joined with our TRI site geometry\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First, we examine the distribution of our Y variable (weighted emissions)\n",
    "\n",
    "yVar = triIG['weighted_emissions']\n",
    "\n",
    "fig = sns.kdeplot(x=yVar)\n",
    "plt.title('Weighted Emissions in Area of Interest, KDE Curve')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% PLOTTING AHEAD\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this plot charts the kernel density of TRI sites, and weights TRI site point size by % of weighted emissions\n",
    "\n",
    "ax = gplt.kdeplot(triIG,\n",
    "                  clip=svi,\n",
    "                  shade=True,\n",
    "                  alpha=.8,\n",
    "                  cmap='inferno',\n",
    "                  figsize=(10, 5),\n",
    "                  kwargs={'thresh':'.1'}\n",
    "                  )\n",
    "gplt.polyplot(svi,\n",
    "              ax=ax,\n",
    "              linewidth=.5,\n",
    "              facecolor=\"black\",\n",
    "              edgecolor='white'\n",
    "              )\n",
    "\n",
    "gplt.pointplot(triIG,\n",
    "               color='white',\n",
    "               ax=ax,\n",
    "               scale=triIG['weighted_emissions'],\n",
    "               limits=(1, 10),\n",
    "               legend=True,\n",
    "               legend_kwargs= {'title': 'Points: TRI Sites\\n% of Weighted Emissions', 'facecolor': 'white', 'loc': 'lower left', 'fancybox': 'True'},)\n",
    "\n",
    "ax.set_title(\"Kernel Density Estimate, TRI Sites in Ramsey County, MN (TRI 2018, EPA)\",\n",
    "             fontsize=16,\n",
    "             color='black')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% TRI SITE & RELEASE PLOT\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# includes Moran's I calculation to quantify spatial autocorrelation in each variable\n",
    "\n",
    "xCandidates = [svi.EP_MINRTY, svi.EP_GROUPQ, svi.EP_DISABL, svi.EP_POV]  # variables of interest\n",
    "\n",
    "colorDict = {0: 'OrRd', 1:'PuRd', 2:'GnBu', 3:'PuBu'}  # consistent color scheme across plots\n",
    "\n",
    "\n",
    "choroCount = 0  # this counter infers the correct colormap\n",
    "\n",
    "# calculate moran's values for display with choropleth maps\n",
    "\n",
    "w = lps.weights.Queen.from_dataframe(svi)  # uses queen weights for moran's\n",
    "w.transform = 'r'  # I'm told this is important\n",
    "\n",
    "moranList = [Moran(cand, w) for cand in xCandidates]  # calculates Moran's for all 4 variables\n",
    "\n",
    "# 4 variables, 4 plots, 2x2 grid\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_size_inches(11,8)\n",
    "\n",
    "fig.suptitle(\"Vulnerability Characteristics, Ramsey County, MN (SVI 2018, CDC)\",\n",
    "             fontsize=20,\n",
    "             fontdict={'color': 'white'})\n",
    "\n",
    "\n",
    "# this loop generates all 4 choropleths and adds them to the figure\n",
    "\n",
    "for cand, ax in zip(xCandidates, axs.flatten()):\n",
    "\n",
    "    scheme = mcs.NaturalBreaks(cand, k=5)  # since we're plotting 4 choropleths, Natural Breaks will highlight groupings\n",
    "\n",
    "    gplt.choropleth(\n",
    "                        svi,\n",
    "                        hue=cand,\n",
    "                        scheme=scheme,\n",
    "                        cmap=colorDict[choroCount],\n",
    "                        linewidth=.5,\n",
    "                        legend=True,\n",
    "                        legend_kwargs={'title': 'Percent of Pop.', 'facecolor': 'white', 'loc': 'upper left', 'fancybox': 'True'},\n",
    "                        ax=ax\n",
    "                        )\n",
    "    choroCount += 1\n",
    "\n",
    "# that's all for the choropleths, now let's label them...\n",
    "\n",
    "axs[0, 0].set_title(\"Minority\",\n",
    "                    color='white',\n",
    "                    fontsize=14)\n",
    "\n",
    "axs[0, 0].annotate(\"Moran's I: {}\\nP-Value: {}\".format(round(moranList[0].I, 2), moranList[0].p_sim),\n",
    "                   xy=(.99, .75),\n",
    "                   xytext=(.9, .75),\n",
    "                   xycoords='axes fraction',\n",
    "                   textcoords='axes fraction',\n",
    "                   color='white')\n",
    "\n",
    "axs[0, 1].set_title(\"Living in Group Quarters\", color='white', fontsize=14)\n",
    "axs[0, 1].annotate(\"Moran's I: {}\\nP-Value: {}\".format(round(moranList[1].I, 2), moranList[1].p_sim),\n",
    "                   xy=(.99, .75),\n",
    "                   xytext=(.9, .75),\n",
    "                   xycoords='axes fraction',\n",
    "                   textcoords='axes fraction',\n",
    "                   color='white')\n",
    "\n",
    "\n",
    "axs[1, 0].set_title(\"Disabled (over age 5)\", color='white', fontsize=14)\n",
    "axs[1, 0].annotate(\"Moran's I: {}\\nP-Value: {}\".format(round(moranList[2].I, 2), moranList[2].p_sim),\n",
    "                   xy=(.99, .75),\n",
    "                   xytext=(.99, .75),\n",
    "                   xycoords='axes fraction',\n",
    "                   textcoords='axes fraction',\n",
    "                   color='white')\n",
    "\n",
    "axs[1, 1].set_title(\"Living in Poverty\", color='white', fontsize=14)\n",
    "axs[1, 1].annotate(\"Moran's I: {}\\nP-Value: {}\".format(round(moranList[3].I, 2), moranList[3].p_sim),\n",
    "                   xy=(.99, .75),\n",
    "                   xytext=(.99, .75),\n",
    "                   xycoords='axes fraction',\n",
    "                   textcoords='axes fraction',\n",
    "                   color='white')\n",
    "\n",
    "fig.set_facecolor('black')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  PREDICTOR PLOTS:  CHOROPLETHS OF DEMOGRAPHIC VARIABLES\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Aha, how to address the problem in this method:  comparing point and polygon objects in the context of GWR.\n",
    "# To provide some gauge of how TRI sites relate to the demographics nearby, the TRI sites are used to generate\n",
    "# voronoi polygons, which contain all points closest to that TRI site.\n",
    "\n",
    "x = triIG.geometry.x.values\n",
    "y = triIG.geometry.y.values\n",
    "triCoords = list(zip(x, y))\n",
    "\n",
    "trifd = pd.Series(triIG.index.to_list(),\n",
    "                  name='trifd')\n",
    "\n",
    "triX = pd.Series(triIG.weighted_emissions.to_list(),\n",
    "                 name='weighted_emissions')\n",
    "\n",
    "regionDF, pointDF = voronoi_frames(triCoords,\n",
    "                                   clip=svi.geometry.unary_union)\n",
    "\n",
    "regionDF.crs = 'EPSG:4326'\n",
    "\n",
    "# the double-merge is ugly, but geopandas and .join are fickle, or I just need more practice.\n",
    "# in any case, these statements merge trifd (site identifier) and values back into the polygons.\n",
    "\n",
    "triVoronoi = pd.merge(regionDF, trifd,\n",
    "                      left_index=True,\n",
    "                      right_index=True)\n",
    "\n",
    "triVoronoi = pd.merge(triVoronoi, triX,\n",
    "                      left_index=True,\n",
    "                      right_index=True)\n",
    "\n",
    "# Once we have these polygons loaded with the Y values, it's time to align our X data.\n",
    "# NOTE:  The spatial join here is a bit rough in terms of representing underlying population distributions.\n",
    "# A much more sophisticated analysis is possible, along the lines of using the underlying population counts\n",
    "# to assign population estimates to voronoi regions based on proportional overlapping area, etc.\n",
    "# as it is, the model proceeds with a rougher vision in the hopes of future refinements.\n",
    "\n",
    "analysisLayer = gpd.sjoin(triVoronoi,\n",
    "                          svi,\n",
    "                          how='left',\n",
    "                          op='contains')\n",
    "\n",
    "# the join method preserves data from both objects, however it also duplicates each polygon in the process.\n",
    "# dissolving via mean allows these values to be collapsed into a singular representative geometry.\n",
    "\n",
    "analysisLayer = analysisLayer.dissolve(by=analysisLayer.trifd,\n",
    "                                       aggfunc='mean')\n",
    "\n",
    "analysisLayer = analysisLayer.fillna(0)  # deals with np.nan issues"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% voronoi regions from tri coords\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Since we're changing geometries, some additional visualization is helpful.\n",
    "\n",
    "scheme = mcs.Quantiles(analysisLayer.weighted_emissions)\n",
    "\n",
    "ax = gplt.choropleth(\n",
    "    analysisLayer,\n",
    "    hue=analysisLayer.weighted_emissions,\n",
    "    scheme=scheme,\n",
    "    cmap='Reds',\n",
    "    linewidth=.5,\n",
    "    legend=True,\n",
    "    legend_kwargs={'title': 'Percent of Weighted Emissions', 'facecolor': 'white', 'loc': 'lower left', 'fancybox': 'True'},\n",
    ")\n",
    "ax.set_title(\"Weighted Emissions (Percent of Total)\\nQuantiles Classification\", size=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% PLOT: weighted emissions by voronoi region\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "choroCount = 0  # reset\n",
    "xCandidates = [analysisLayer.EP_MINRTY, analysisLayer.EP_GROUPQ, analysisLayer.EP_DISABL, analysisLayer.EP_POV]  # variables of interest\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.set_size_inches(11,8)\n",
    "\n",
    "fig.suptitle(\"Vulnerability Characteristics, Voronoi Dissolve (SVI 2018, CDC)\",\n",
    "             fontsize=20,\n",
    "             fontdict={'color': 'white'})\n",
    "\n",
    "for cand, ax in zip(xCandidates, axs.flatten()):\n",
    "\n",
    "    scheme = mcs.NaturalBreaks(cand, k=5)  # since we're plotting 4 choropleths, Natural Breaks will highlight groupings\n",
    "\n",
    "    gplt.choropleth(\n",
    "                        analysisLayer,\n",
    "                        hue=cand,\n",
    "                        scheme=scheme,\n",
    "                        cmap=colorDict[choroCount],\n",
    "                        linewidth=.5,\n",
    "                        legend=True,\n",
    "                        legend_kwargs={'title': 'Percent of Pop.', 'facecolor': 'white', 'loc': 'upper left', 'fancybox': 'True'},\n",
    "                        ax=ax\n",
    "                        )\n",
    "    choroCount += 1\n",
    "\n",
    "# that's all for the choropleths, now let's label them...\n",
    "\n",
    "axs[0, 0].set_title(\"Minority\",\n",
    "                    color='white',\n",
    "                    fontsize=14\n",
    "                    )\n",
    "\n",
    "axs[0, 1].set_title(\"Living in Group Quarters\",\n",
    "                    color='white',\n",
    "                    fontsize=14\n",
    "                    )\n",
    "\n",
    "axs[1, 0].set_title(\"Disabled (over age 5)\",\n",
    "                    color='white', fontsize=14\n",
    "                    )\n",
    "\n",
    "axs[1, 1].set_title(\"Living in Poverty\",\n",
    "                    color='white',\n",
    "                    fontsize=14\n",
    "                    )\n",
    "\n",
    "fig.set_facecolor('black')\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# At last!  Extract centroids, compute values, regress, report, awesome.\n",
    "\n",
    "centroids = analysisLayer.centroid  # center of voronoi region = xy of TRI site\n",
    "\n",
    "y = analysisLayer['weighted_emissions'].values.reshape((-1, 1))  # normalize values\n",
    "X = analysisLayer[['EP_MINRTY', \"EP_GROUPQ\", \"EP_DISABL\", 'EP_POV']].values # predictors\n",
    "u = centroids.x.values\n",
    "v = centroids.y.values\n",
    "triCoords = list(zip(u, v))\n",
    "\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)  # normalizing\n",
    "\n",
    "y = (y - y.mean(axis=0)) / y.std(axis=0)  # normalizing\n",
    "\n",
    "gwrSelector = Sel_BW(triCoords, y, X)  # bandwidth selection\n",
    "gwrBW = gwrSelector.search(bw_min=2)\n",
    "print('bandwidth: {}'.format(gwrBW))  # report bandwidth\n",
    "\n",
    "gwrResults = GWR(triCoords,\n",
    "                 y,\n",
    "                 X,\n",
    "                 gwrBW,\n",
    "                 kernel='gaussian',\n",
    "                 spherical=True\n",
    "                 ).fit()  # huzzah!  a regression!\n",
    "\n",
    "print(gwrResults.summary())  # results summary.  compare output to subsequent coefficent maps to assess validity.\n",
    "\n",
    "# coefficient capture\n",
    "int = analysisLayer['gwr_int'] = gwrResults.params[:, 0]\n",
    "minority = analysisLayer['gwr_min'] = gwrResults.params[:, 1]\n",
    "groupQ = analysisLayer['gwr_groupq'] = gwrResults.params[:, 2]\n",
    "disabl = analysisLayer['gwr_disabl'] = gwrResults.params[:, 3]\n",
    "poverty = analysisLayer['gwr_pov'] = gwrResults.params[:, 4]\n",
    "\n",
    "\n",
    "\n",
    "#residuals capture\n",
    "triIG['resid'] = gwrResults.resid_response\n",
    "\n",
    "\n",
    "# Create scalar mappable for colorbar and stretch colormap across range of data values\n",
    "\n",
    "coefCandidates = [minority, groupQ, disabl, poverty]\n",
    "\n",
    "coefMins = [np.min(i) for i in coefCandidates]\n",
    "coefMaxs = [np.max(i) for i in coefCandidates]\n",
    "\n",
    "vMin = np.min(coefMins)\n",
    "vMax = np.max(coefMaxs)\n",
    "\n",
    "cmap = plt.cm.coolwarm\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap,\n",
    "                           norm=plt.Normalize(\n",
    "                               vmin=vMin,\n",
    "                               vmax=vMax\n",
    "                                )\n",
    "                           )\n",
    "\n",
    " #%%  Finally, we plot coefficents.  The residuals are depicted by TRI site point size.\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(11, 8)\n",
    "\n",
    "fig.suptitle(\"GWR Model Parameters:  Coefficient values, residuals (point size)\",\n",
    "             fontsize=20,\n",
    "             color='black'\n",
    "             )\n",
    "\n",
    "coefFlag = 0\n",
    "\n",
    "coefCandidates = [minority, groupQ, disabl, poverty]\n",
    "\n",
    "for coef, ax in zip(coefCandidates, axs.flatten()):\n",
    "\n",
    "    scheme = mcs.NaturalBreaks(coef,\n",
    "                               k=5)\n",
    "\n",
    "    gplt.pointplot(\n",
    "        triIG,\n",
    "        scale=triIG['resid'],\n",
    "        color='black',\n",
    "        limits=(1, 20),\n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    gplt.choropleth(\n",
    "                    analysisLayer,\n",
    "                    hue=coef,\n",
    "                    scheme=scheme,\n",
    "                    cmap=cmap,\n",
    "                    linewidth=.5,\n",
    "                    ax=ax,\n",
    "                    alpha=.8,\n",
    "                    )\n",
    "\n",
    "axs[0, 0].set_title(\"Minority\",\n",
    "                    color='black',\n",
    "                    fontsize=14)\n",
    "\n",
    "axs[0, 1].set_title(\"Living in Group Quarters\",\n",
    "                    color='black',\n",
    "                    fontsize=14)\n",
    "\n",
    "axs[1, 0].set_title(\"Disabled (over age 5)\",\n",
    "                    color='black',\n",
    "                    fontsize=14)\n",
    "\n",
    "axs[1, 1].set_title(\"Living in Poverty\",\n",
    "                    color='black',\n",
    "                    fontsize=14)\n",
    "\n",
    "\n",
    "# Set figure options and plot\n",
    "cax = fig.add_axes([0.9, 0.1, 0.02, 0.75])\n",
    "\n",
    "cbar = fig.colorbar(sm,\n",
    "                    cax=cax)\n",
    "\n",
    "cbar.ax.tick_params(labelsize=14)\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% GWR HAPPENS HERE\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = sns.displot(data=triIG['resid'])\n",
    "plt.show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for cand in xCandidates:\n",
    "\n",
    "    sns.residplot(y, cand, color='blue')\n",
    "    plt.show\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}